{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "x,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GD:\n",
    "    def __init__(self,lr=0.01,epochs=1000):\n",
    "        self.lr=lr\n",
    "        self.epochs=epochs\n",
    "        self.coeff_=None\n",
    "        self.intercept_=None\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.intercept_=0\n",
    "        self.coeff_=np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            y_pred=self.intercept_+ np.dot(x_train,self.coeff_)\n",
    "            der=-2*np.mean(y_train-y_pred)\n",
    "            self.intercept_=self.intercept_ - (self.lr*der)\n",
    "            # coeffs\n",
    "            coeff_der=-2*(np.dot((y_train-y_pred),x_train)/(x_train.shape[0]))\n",
    "            self.coeff_=self.coeff_- (self.lr*coeff_der)\n",
    "          \n",
    "        print(self.intercept_,self.coeff_)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.coeff_)+self.intercept_        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.94042847773682 [  62.27835432  -24.14017912  262.40285385  192.20751489   39.48809013\n",
      "   10.26886323 -142.50597903  124.33312557  244.33510843  119.34350233]\n"
     ]
    }
   ],
   "source": [
    "gd=GD(lr=0.1,epochs=1000)\n",
    "gd.fit(X_train,y_train)\n",
    "y_pred=gd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3971698388048742"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self,lr=0.01,epochs=100):\n",
    "        self.lr=lr\n",
    "        self.epochs=epochs\n",
    "        self.coeff_=None\n",
    "        self.intercept_=None\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.intercept_=0\n",
    "        self.coeff_=np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for i in range(x_train.shape[0]):\n",
    "                idx=np.random.randint(0,x_train.shape[0])\n",
    "                y_pred=self.intercept_+ np.dot(x_train[idx],self.coeff_)\n",
    "                der=-2*(y_train[idx]-y_pred)\n",
    "                self.intercept_=self.intercept_ -(self.lr*der)\n",
    "                # coeffs\n",
    "                coeff_der=-2*np.dot((y_train[idx]-y_pred),x_train[idx])\n",
    "                self.coeff_=self.coeff_-(self.lr*coeff_der)\n",
    "          \n",
    "        print(self.intercept_,self.coeff_)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.coeff_)+self.intercept_   \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.61866159247623 [ -30.37768989 -200.38344145  520.82406878  305.62249326 -679.66298549\n",
      "  385.2728342    41.57957112  122.94114919  799.12883913   66.37788179]\n"
     ]
    }
   ],
   "source": [
    "sgd=SGD(lr=0.1,epochs=1000)\n",
    "sgd.fit(X_train,y_train)\n",
    "y_preds=sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43214246386953103"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MbGD:\n",
    "    def __init__(self,lr=0.01,epochs=100,batch_size=10):\n",
    "        self.lr=lr\n",
    "        self.epochs=epochs\n",
    "        self.coeff_=None\n",
    "        self.intercept_=None\n",
    "        self.batch_size=batch_size\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.intercept_=0\n",
    "        self.coeff_=np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for i in range(int(x_train.shape[0]/self.batch_size)):\n",
    "                idx=random.sample(range(x_train.shape[0]),self.batch_size)\n",
    "                y_pred=self.intercept_+ np.dot(x_train[idx],self.coeff_)\n",
    "                intercept_der=-2*np.mean(y_train[idx]-y_pred)\n",
    "                self.intercept_=self.intercept_ -(self.lr*intercept_der)\n",
    "                # coeffs\n",
    "                coeff_der=-2*np.dot((y_train[idx]-y_pred),x_train[idx])\n",
    "                self.coeff_=self.coeff_-(self.lr*coeff_der)\n",
    "          \n",
    "        print(self.intercept_,self.coeff_)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.coeff_)+self.intercept_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.28225316070618 [  22.87544171 -191.08749302  521.37811617  320.50266206 -815.87987543\n",
      "  488.84779157  130.45700654  115.51161157  851.83257146   20.28693168]\n"
     ]
    }
   ],
   "source": [
    "Mbgd=MbGD(lr=0.2,epochs=1000,batch_size=100)\n",
    "Mbgd.fit(X_train,y_train)\n",
    "y_predm=Mbgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4352881068611383"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
